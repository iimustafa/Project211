{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stadium Crowd Behavior Detection System - Colab Demo\n",
    "\n",
    "This notebook demonstrates how to use the Stadium Crowd Behavior Detection System in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "First, let's upload and extract the system files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload the zip file\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # Select the stadium_crowd_detection.zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Unzip the file\n",
    "!unzip stadium_crowd_detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "!pip install tensorflow opencv-python pillow matplotlib numpy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Dataset\n",
    "\n",
    "Let's generate a synthetic dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Add the project directory to the path\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('stadium_crowd_detection')\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p stadium_crowd_detection/stadium_dataset\n",
    "!mkdir -p stadium_crowd_detection/stadium_dataset/images\n",
    "!mkdir -p stadium_crowd_detection/stadium_dataset/annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the synthetic dataset generation code\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "BASE_DIR = 'stadium_crowd_detection/stadium_dataset'\n",
    "\n",
    "def generate_fan(team='hilal', action='sitting'):\n",
    "    \"\"\"\n",
    "    Creates a cartoon fan as a colored stick figure.\n",
    "    \"\"\"\n",
    "    img = Image.new('RGBA', (128, 128), (255, 255, 255, 0))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Team color\n",
    "    color = (0, 0, 255) if team == 'hilal' else (255, 215, 0)\n",
    "\n",
    "    # Head\n",
    "    draw.ellipse((50, 10, 78, 38), fill=(255, 224, 189))\n",
    "\n",
    "    # Body\n",
    "    draw.rectangle((60, 38, 68, 90), fill=color)\n",
    "\n",
    "    # Action variations\n",
    "    if action == 'cheering':\n",
    "        # Arms up\n",
    "        draw.line((60, 40, 30, 20), fill=color, width=5)\n",
    "        draw.line((68, 40, 98, 20), fill=color, width=5)\n",
    "    elif action == 'throwing':\n",
    "        draw.line((60, 40, 90, 35), fill=color, width=5)\n",
    "        draw.line((68, 40, 70, 70), fill=color, width=5)\n",
    "    elif action == 'fighting':\n",
    "        draw.line((60, 40, 40, 50), fill=color, width=5)\n",
    "        draw.line((68, 40, 85, 50), fill=color, width=5)\n",
    "    else:  # Sitting\n",
    "        draw.line((60, 40, 40, 60), fill=color, width=5)\n",
    "        draw.line((68, 40, 90, 60), fill=color, width=5)\n",
    "\n",
    "    return img\n",
    "\n",
    "def create_stadium_background(filled=True):\n",
    "    \"\"\"\n",
    "    Generates a basic stadium stand background.\n",
    "    \"\"\"\n",
    "    img = Image.new('RGB', (512, 384), (150, 150, 150))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Seat rows\n",
    "    for y in range(100, 350, 30):\n",
    "        draw.rectangle((10, y, 502, y + 20), fill=(80, 80, 80))\n",
    "\n",
    "    return img\n",
    "\n",
    "# Generate a smaller dataset for demo purposes\n",
    "annotations = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\"id\": 1, \"name\": \"fan\", \"supercategory\": \"person\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "fan_id = 1\n",
    "image_id = 1\n",
    "\n",
    "# Generate 20 images for the demo\n",
    "for i in range(20):\n",
    "    bg = create_stadium_background(filled=True)\n",
    "    fans = []\n",
    "    num_fans = random.randint(3, 8)\n",
    "\n",
    "    boxes = []\n",
    "    for _ in range(num_fans):\n",
    "        team = random.choice(['hilal', 'ittihad'])\n",
    "        action = random.choice(['sitting', 'cheering', 'fighting', 'throwing'])\n",
    "\n",
    "        fan_img = generate_fan(team, action)\n",
    "        x = random.randint(20, 400)\n",
    "        y = random.randint(120, 300)\n",
    "        bg.paste(fan_img, (x, y), fan_img)\n",
    "\n",
    "        # Save bbox for labeling\n",
    "        boxes.append({\n",
    "            \"bbox\": [x, y, 128, 128],\n",
    "            \"category_id\": 1,\n",
    "            \"id\": fan_id,\n",
    "            \"image_id\": image_id,\n",
    "            \"attributes\": {\"team\": team, \"action\": action}\n",
    "        })\n",
    "\n",
    "        fan_id += 1\n",
    "\n",
    "    # Save image\n",
    "    img_path = f\"{BASE_DIR}/images/{image_id:04d}.png\"\n",
    "    bg.save(img_path)\n",
    "\n",
    "    annotations[\"images\"].append({\n",
    "        \"id\": image_id,\n",
    "        \"file_name\": f\"{image_id:04d}.png\",\n",
    "        \"width\": 512,\n",
    "        \"height\": 384\n",
    "    })\n",
    "\n",
    "    annotations[\"annotations\"].extend(boxes)\n",
    "    image_id += 1\n",
    "\n",
    "# Save annotations\n",
    "with open(f\"{BASE_DIR}/annotations/labels.json\", \"w\") as f:\n",
    "    json.dump(annotations, f, indent=2)\n",
    "\n",
    "print(f\"Generated {len(annotations['images'])} images with {len(annotations['annotations'])} fan annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Models\n",
    "\n",
    "Now let's train the models on our synthetic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create models directory\n",
    "!mkdir -p stadium_crowd_detection/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the training script with a smaller number of epochs for demo purposes\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from stadium_crowd_detection.src.data_utils import StadiumDataset\n",
    "from stadium_crowd_detection.src.model import FanDetectionModel\n",
    "\n",
    "# Configuration\n",
    "DATASET_DIR = 'stadium_crowd_detection/stadium_dataset'\n",
    "MODEL_DIR = 'stadium_crowd_detection/models'\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 5  # Reduced for demo\n",
    "INPUT_SHAPE = (384, 512, 3)  # Height, width, channels\n",
    "\n",
    "# Load and prepare the dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset = StadiumDataset(DATASET_DIR, image_size=(512, 384))\n",
    "dataset.load_annotations()\n",
    "\n",
    "# Visualize a sample image\n",
    "print(\"Visualizing a sample image...\")\n",
    "sample_id = dataset.image_ids[0]\n",
    "dataset.visualize_sample(sample_id)\n",
    "\n",
    "# Prepare datasets for training\n",
    "print(\"Preparing datasets for training...\")\n",
    "train_dataset, val_dataset = dataset.prepare_detection_dataset(\n",
    "    train_ratio=0.8, \n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Build and train the model\n",
    "print(\"Building model...\")\n",
    "model = FanDetectionModel(input_shape=INPUT_SHAPE)\n",
    "model.build_model()\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(MODEL_DIR, 'fan_detection_model.h5'),\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss'\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=3,\n",
    "        monitor='val_loss'\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        factor=0.2,\n",
    "        patience=2,\n",
    "        monitor='val_loss'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "print(\"Training model...\")\n",
    "history = model.train(\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(f\"Model training completed. Model saved to {os.path.join(MODEL_DIR, 'fan_detection_model.h5')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the System\n",
    "\n",
    "Now let's test our system on some of the synthetic images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create test directories\n",
    "!mkdir -p stadium_crowd_detection/test_results\n",
    "!mkdir -p stadium_crowd_detection/alerts\n",
    "!mkdir -p stadium_crowd_detection/alerts/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the system on a sample image\n",
    "from stadium_crowd_detection.src.system import StadiumMonitoringSystem\n",
    "\n",
    "# Initialize the system\n",
    "system = StadiumMonitoringSystem(config={\n",
    "    'model_dir': 'stadium_crowd_detection/models',\n",
    "    'alerts_dir': 'stadium_crowd_detection/alerts',\n",
    "    'stadium_sections': {\n",
    "        'hilal': [0, 0, 256, 384],  # Left half of stadium\n",
    "        'ittihad': [256, 0, 512, 384]  # Right half of stadium\n",
    "    }\n",
    "})\n",
    "\n",
    "# Initialize with the trained model\n",
    "system.initialize(detector_path='stadium_crowd_detection/models/fan_detection_model.h5')\n",
    "\n",
    "# Get a sample image path\n",
    "sample_image = f\"{DATASET_DIR}/images/0001.png\"\n",
    "\n",
    "# Process the image\n",
    "output_path = \"stadium_crowd_detection/test_results/sample_output.png\"\n",
    "detections, alerts = system.process_image(\n",
    "    sample_image,\n",
    "    output_path=output_path,\n",
    "    generate_alerts=True\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(f\"Detected {len(detections)} fans\")\n",
    "print(f\"Generated {len(alerts)} alerts\")\n",
    "\n",
    "# Display the output image\n",
    "from IPython.display import Image\n",
    "Image(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Alert Report\n",
    "\n",
    "Let's generate a report of the alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate and display alert report\n",
    "report = system.generate_report()\n",
    "print(report)\n",
    "\n",
    "# Visualize alert distribution\n",
    "fig = system.visualize_alerts(\"stadium_crowd_detection/test_results/alert_distribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Multiple Images\n",
    "\n",
    "Let's process multiple images from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process multiple images\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = glob.glob(f\"{DATASET_DIR}/images/*.png\")\n",
    "print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "# Process a subset of images\n",
    "for i, image_path in enumerate(image_paths[:5]):\n",
    "    print(f\"Processing image {i+1}/{len(image_paths[:5])}: {os.path.basename(image_path)}\")\n",
    "    \n",
    "    output_path = f\"stadium_crowd_detection/test_results/output_{i+1}.png\"\n",
    "    detections, alerts = system.process_image(\n",
    "        image_path,\n",
    "        output_path=output_path,\n",
    "        generate_alerts=True\n",
    "    )\n",
    "    \n",
    "    print(f\"  Detected {len(detections)} fans\")\n",
    "    print(f\"  Generated {len(alerts)} alerts\")\n",
    "    \n",
    "    # Display the output image\n",
    "    display(Image(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using the Camera in Colab (Optional)\n",
    "\n",
    "If you want to test with a live camera in Colab, you can use the following code to capture an image and process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Capture an image from the webcam\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "        async function takePhoto(quality) {\n",
    "            const div = document.createElement('div');\n",
    "            const capture = document.createElement('button');\n",
    "            capture.textContent = 'Capture';\n",
    "            div.appendChild(capture);\n",
    "\n",
    "            const video = document.createElement('video');\n",
    "            video.style.display = 'block';\n",
    "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "            document.body.appendChild(div);\n",
    "            div.appendChild(video);\n",
    "            video.srcObject = stream;\n",
    "            await video.play();\n",
    "\n",
    "            // Resize the output to fit the video element.\n",
    "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "            // Wait for Capture to be clicked.\n",
    "            await new Promise((resolve) => {\n",
    "                capture.onclick = resolve;\n",
    "            });\n",
    "\n",
    "            const canvas = document.createElement('canvas');\n",
    "            canvas.width = video.videoWidth;\n",
    "            canvas.height = video.videoHeight;\n",
    "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "            stream.getVideoTracks()[0].stop();\n",
    "            div.remove();\n",
    "            return canvas.toDataURL('image/jpeg', quality);\n",
    "        }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename\n",
    "\n",
    "# Take a photo\n",
    "try:\n",
    "    filename = take_photo('stadium_crowd_detection/test_results/webcam.jpg')\n",
    "    print('Saved to {}'.format(filename))\n",
    "    \n",
    "    # Display the photo\n",
    "    display(Image(filename))\n",
    "    \n",
    "    # Process the image\n",
    "    output_path = \"stadium_crowd_detection/test_results/webcam_output.jpg\"\n",
    "    detections, alerts = system.process_image(\n",
    "        filename,\n",
    "        output_path=output_path,\n",
    "        generate_alerts=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Detected {len(detections)} fans\")\n",
    "    print(f\"Generated {len(alerts)} alerts\")\n",
    "    \n",
    "    # Display the output image\n",
    "    display(Image(output_path))\n",
    "    \n",
    "except Exception as e:\n",
    "    print('An error occurred: {}'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook demonstrated how to use the Stadium Crowd Behavior Detection System in Google Colab. You can extend this demo by:\n",
    "\n",
    "1. Training the models for more epochs to improve accuracy\n",
    "2. Processing videos instead of just images\n",
    "3. Modifying the system to detect additional behaviors or team affiliations\n",
    "4. Integrating with other systems or APIs\n",
    "\n",
    "For more information, refer to the README.md file in the project repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
